{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data load\n",
    "> Core modifications for making the dataloader work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODOs:\n",
    "* Should not modify main dataloader, but instead subclass it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import fastai2.imports\n",
    "import fastcore.imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# def is_iter(o):\n",
    "#     \"Test whether `o` can be used in a `for` loop\"\n",
    "#     res = True\n",
    "#     try: iter(o)\n",
    "#     except TypeError: res = False\n",
    "#     #Rank 0 tensors in PyTorch are not really iterable\n",
    "#     return res and getattr(o,'ndim',1)\n",
    "# fastai2.imports.is_iter = is_iter\n",
    "# fastcore.imports.is_iter = is_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai2.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Bucket:\n",
    "    def __init__(self, items): self.items = items\n",
    "    def __repr__(self): return f'<{self.__class__.__name__}: {self.items.__repr__()}>'\n",
    "#     def __getitem__(self, i): return L.__getitem__(self, i)\n",
    "    def __getitem__(self, idx): return self._get(idx) if is_indexer(idx) else Bucket(self._get(idx))\n",
    "    def _get(self, i):\n",
    "        if is_indexer(i) or isinstance(i,slice): return getattr(self.items,'iloc',self.items)[i]\n",
    "        i = mask2idxs(i)\n",
    "        return (self.items.iloc[list(i)] if hasattr(self.items,'iloc')\n",
    "                else self.items.__array__()[(i,)] if hasattr(self.items,'__array__')\n",
    "                else [self.items[i_] for i_ in i])\n",
    "#     def __iter__(self): raise TypeError(f\"'{self.__class__.__name__}' object is not iterable\")\n",
    "    def __eq__(self, other): return self.items == other\n",
    "    def __len__(self): return len(self.items)\n",
    "    def tolist(self): return list(self.items)\n",
    "    def map(self, f): return type(self)(type(self.items)(f(o) for o in self.items))\n",
    "    def to_device(self, device): return type(self)(to_device(self.items))\n",
    "    @property\n",
    "    def shape(self): return (len(self.items),) # Needed for find_bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_bucket(items):\n",
    "#     name = items[0].__class__.__name__ + 'Bucket'\n",
    "#     return type(name, (Bucket,), {})\n",
    "    return Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class _Buckets(dict):\n",
    "    def __getitem__(self, k):\n",
    "        try: return super().__getitem__(type(k[0]))(k)\n",
    "        except KeyError:\n",
    "            v = self[type(k[0])] = create_bucket(k)\n",
    "            return v(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = _Buckets()\n",
    "b1 = buckets[['a', 'b']]\n",
    "b2 = buckets[['c', 'd']]\n",
    "test_eq(type(b1), type(b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(b1[0], 'a')\n",
    "test_eq(b2[1], 'd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(b1[0,1], Bucket(['a','b']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_fail(lambda: [o for o in b1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(is_iter(b1), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(b1.map(lambda o: o+'foo'), Bucket(['afoo', 'bfoo']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(b1.shape, (2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_buckets = _Buckets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def bucketify(items): return _buckets[items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _bucket_collate(t): return Tuple(bucketify(o) for o in zip(*t))\n",
    "def _bucket_convert(t): raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def detect_batch_to_samples(b, max_n=10):\n",
    "    zipped = []\n",
    "    for i in range(min(len(b[0]), max_n)):\n",
    "        zipped.append(Tuple([o[i] for o in b]))\n",
    "    return zipped\n",
    "#     return L(b).zip()[:max_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DetectDataLoader(TfmdDL):\n",
    "    def create_batch(self, b): return (_bucket_collate,_bucket_convert)[self.prebatched](b)\n",
    "    \n",
    "    def _decode_batch(self, b, max_n=9, full=True):\n",
    "        f = self.after_item.decode\n",
    "        f = compose(f, partial(getattr(self.dataset,'decode',noop), full = full))\n",
    "        return L(detect_batch_to_samples(b, max_n=max_n)).map(f)\n",
    "    \n",
    "#     def _one_pass(self):\n",
    "#         res = super()._one_pass()\n",
    "#         self._types = {Tuple: [tuple, tuple]} # HACK\n",
    "#         return res\n",
    "    \n",
    "    def show_batch(self, b=None, max_n=9, ctxs=None, show=True, unique=False, **kwargs):\n",
    "        if unique:\n",
    "            old_get_idxs = self.get_idxs\n",
    "            self.get_idxs = lambda: Inf.zeros\n",
    "        if b is None: b = self.one_batch()\n",
    "        if not show: return self._pre_show_batch(b, max_n=max_n)\n",
    "        show = show_batch[type(b[0][0]), type(b[1][0])]\n",
    "        pb = self._pre_show_batch(b, max_n=max_n)\n",
    "        show(*pb, ctxs=ctxs, max_n=max_n, **kwargs)\n",
    "        if unique: self.get_idxs = old_get_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = np.arange(20).reshape(10,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Letter:\n",
    "    def __init__(self, v): self.v = v\n",
    "    def __repr__(self): return f'<Letter: {self.v.__repr__()}>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = L(string.ascii_lowercase, use_list=True).map(Letter)\n",
    "numbers = L(range_of(letters))\n",
    "dset = list(zip(letters,numbers)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders.from_dsets(dset, bs=3, dl_type=DetectDataLoader, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(first(dls.train), (bucketify(Tuple(letters[:3])), bucketify(Tuple(numbers[:3]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<Letter: 'a'>, 0), (<Letter: 'b'>, 1)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_batch_to_samples(b, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = [[tensor(1), tensor(2)], [tensor(1), tensor(2)]]\n",
    "dls = DataLoaders.from_dsets(dset, bs=2, dl_type=DetectDataLoader, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb,yb = dls.one_batch()\n",
    "xb[0].is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for b in progress_bar(dls.train): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "old_do_call = Transform._do_call\n",
    "def _do_call(self, f, x, **kwargs):\n",
    "    if isinstance(x, Bucket):\n",
    "        _f = lambda o: retain_type(f(o, **kwargs), o, f.returns_none(o))\n",
    "        return x if f is None else x.map(_f)\n",
    "    return old_do_call(self, f, x, **kwargs)\n",
    "Transform._do_call = _do_call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 03_data.load.ipynb.\n",
      "Converted 04_data.core.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
